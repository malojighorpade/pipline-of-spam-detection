{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a772d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maloj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maloj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\maloj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9885104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44e6b6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "567f7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e4d08f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'v1':'label', 'v2':'message'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aec1bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['label']=le.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ccfe6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9179aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates(keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32d4cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "591b45f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  transform_text(message):\n",
    "    message=message.lower()\n",
    "    message=nltk.word_tokenize(message)\n",
    "    y=[]\n",
    "    for i in message:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "    message=y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in message:\n",
    "            if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "                y.append(ps.stem(i))\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "757f6d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>transformed_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  \\\n",
       "0      0  Go until jurong point, crazy.. Available only ...   \n",
       "1      0                      Ok lar... Joking wif u oni...   \n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      0  U dun say so early hor... U c already then say...   \n",
       "4      0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                 transformed_message  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4               nah think goe usf live around though  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transformed_message']=df['message'].apply(transform_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3af2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "tfidf=TfidfVectorizer(max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98cf7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tfidf.fit_transform(df['transformed_message']).toarray()\n",
    "y=df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23f63929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.20,random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e2b7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b23d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc= SVC(kernel=\"sigmoid\",gamma=1.0)\n",
    "knc=KNeighborsClassifier()\n",
    "mnb=MultinomialNB()\n",
    "dtc=DecisionTreeClassifier(max_depth=5)\n",
    "rfc=RandomForestClassifier(n_estimators=50,random_state=2)\n",
    "lrc=LogisticRegression(solver='liblinear',penalty='l1')\n",
    "abc=AdaBoostClassifier(n_estimators=50,random_state=2)\n",
    "bgc=BaggingClassifier(n_estimators=50,random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "848c302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs={\n",
    "    'SVC':svc,\n",
    "    'KNC':knc,\n",
    "    'MNB':mnb,\n",
    "    'DTC':dtc,\n",
    "    'RFC':rfc,\n",
    "    'LRC':lrc,\n",
    "    'ABC':abc,\n",
    "    'BGC':bgc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3fb9ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score\n",
    "def train_classifier(clfs,X_train,y_train,X_test,y_test):\n",
    "    clfs.fit(X_train,y_train)\n",
    "    y_pred=clfs.predict(X_test)\n",
    "    acccurecy=accuracy_score(y_test,y_pred)\n",
    "    precision=precision_score(y_test,y_pred)\n",
    "    return acccurecy,precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9c00238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For  SVC\n",
      "Accuracy : 0.9661508704061895\n",
      "Precision : 0.9327731092436975\n",
      "\n",
      "For  KNC\n",
      "Accuracy : 0.9274661508704062\n",
      "Precision : 1.0\n",
      "\n",
      "For  MNB\n",
      "Accuracy : 0.9709864603481625\n",
      "Precision : 0.9655172413793104\n",
      "\n",
      "For  DTC\n",
      "Accuracy : 0.9361702127659575\n",
      "Precision : 0.9\n",
      "\n",
      "For  RFC\n",
      "Accuracy : 0.971953578336557\n",
      "Precision : 0.943089430894309\n",
      "\n",
      "For  LRC\n",
      "Accuracy : 0.9622823984526112\n",
      "Precision : 0.9541284403669725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\maloj\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For  ABC\n",
      "Accuracy : 0.9613152804642167\n",
      "Precision : 0.9375\n",
      "\n",
      "For  BGC\n",
      "Accuracy : 0.965183752417795\n",
      "Precision : 0.9180327868852459\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores=[]\n",
    "pression_scores=[]\n",
    "for name,clfs in clfs.items():\n",
    "    current_accuracy,current_precision=train_classifier(clfs,X_train,y_train,X_test,y_test)\n",
    "    print()\n",
    "    print(\"For \",name)\n",
    "    print(\"Accuracy :\",current_accuracy)\n",
    "    print(\"Precision :\",current_precision)\n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    pression_scores.append(current_precision)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ace4c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_spam(message):\n",
    "    cleaned = transform_text(message)\n",
    "    vector = tfidf.transform([cleaned])\n",
    "    result = rfc.predict(vector)\n",
    "    \n",
    "    return \"SPAM\" if result[0] == 1 else \"HAM\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7125d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HAM'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_spam(\"Hey, are we meeting today?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96b84ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPAM'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_spam(\"Free prize!!! Click win now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7413215",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
